#include "../ShaderLibrary/Common.hlsl"
#pragma kernel PureDepthSSAO
#pragma kernel SSAO
#pragma kernel HBAO
#pragma kernel BilateralFilter

RWTexture2D<float3> AmbientOcclusionRT;
RWTexture2D<float3> FilteredResult;
Texture2D<float3> RandomTexture;
Texture2D<float3> aoResult;
float4x4 _CameraProjection;
float4x4 _CameraInverseProjection;
//shared properties
int sampleCount;
int downSample;
float aoRadius;
float2 filterRadius;
float filterFactor;
//pure depth method properties
float threshold;
float area;
float strength;
float correction;
//ssao method properties
float bias;
float contrast;
float magnitude;
float power;
//hbao method properties
float CameraNearPlane;
int numDirections;
int maxRadiusPixels;
float tanBias;
float hbaoStrength;

//refer to : https://theorangeduck.com/page/pure-depth-ssao
float3 normalFromDepth(float depth, float2 texCoords) {
    const float2 offset1 = float2(0.0, 0.001);
    const float2 offset2 = float2(0.001, 0.0);
    float depth1 = LinearEyeDepth(SAMPLE_TEXTURE2D_LOD(_CameraDepthTexture, sampler_point_clamp, texCoords + offset1, 0), _ZBufferParams);
    float depth2 = LinearEyeDepth(SAMPLE_TEXTURE2D_LOD(_CameraDepthTexture, sampler_point_clamp, texCoords + offset2, 0), _ZBufferParams);
    float3 p1 = float3(offset1, depth1 - depth);
    float3 p2 = float3(offset2, depth2 - depth);
    float3 normal = cross(p1, p2);
    normal.z = -normal.z;
    return normalize(normal);
}

float3 UvToViewSpace(float2 uv, float depth) {
    //calculate camera to far plane ray in the screen
    float4 cameraRay = float4(uv * 2.0 - 1.0, 1.0, 1.0);
    cameraRay = mul(_CameraInverseProjection, cameraRay);
    cameraRay.xyz = cameraRay.xyz / cameraRay.w;
    return cameraRay.xyz * depth;
}

[numthreads(8,8,1)]
void PureDepthSSAO(uint3 id : SV_DispatchThreadID) {
    float3 sample_sphere[16] = {
        float3(0.5381, 0.1856,-0.4319), float3(0.1379, 0.2486, 0.4430),
        float3(0.3371, 0.5679,-0.0057), float3(-0.6999,-0.0451,-0.0019),
        float3(0.0689,-0.1598,-0.8547), float3(0.0560, 0.0069,-0.1843),
        float3(-0.0146, 0.1402, 0.0762), float3(0.0100,-0.1924,-0.0344),
        float3(-0.3577,-0.5301,-0.4358), float3(-0.3169, 0.1063, 0.0158),
        float3(0.0103,-0.5869, 0.0046), float3(-0.0897,-0.4940, 0.3287),
        float3(0.7119,-0.0154,-0.0918), float3(-0.0533, 0.0596,-0.5411),
        float3(0.0352,-0.0631, 0.5460), float3(-0.4776, 0.2847,-0.0271)
    };
    //[0,_CameraBufferSize-1] -> screen [0,1] uv
    float2 screenUV = id.xy / (_CameraBufferSize.zw / downSample);
    float rawDepth = SAMPLE_TEXTURE2D_LOD(_CameraDepthTexture, sampler_point_clamp, screenUV, 0);
    float linearDepth = LinearEyeDepth(rawDepth, _ZBufferParams);
    float3 random = normalize(SAMPLE_TEXTURE2D_LOD(RandomTexture, sampler_linear_clamp, screenUV, 0).rgb);
    random = normalize(SAMPLE_TEXTURE2D_LOD(RandomTexture, sampler_linear_repeat, screenUV + random, 0).rgb);
    float3 position = float3(screenUV, linearDepth);
    float3 normal = normalFromDepth(linearDepth, screenUV);
    //near big far small
    float sampleRadius = aoRadius / linearDepth;
    float occlusion = 0.0;
    for (int i = 0; i < 16; i++) {
        float3 ray = sampleRadius * reflect(sample_sphere[i], random);
        float3 hemiRay = position + sign(dot(ray, normal)) * ray;
        float occlusionDepth = LinearEyeDepth(SAMPLE_TEXTURE2D_LOD(_CameraDepthTexture, sampler_point_clamp, saturate(hemiRay.xy), 0), _ZBufferParams);
        float difference = linearDepth - occlusionDepth;
        occlusion += step(threshold, difference) * (1.0 - smoothstep(threshold, area, length(ray)));
    }
    float ao = 1 - strength * occlusion / 16;
    ao = saturate(ao + correction);
    AmbientOcclusionRT[id.xy] = ao.xxx;
}

//there are many methods about SSAO,such as sphere-sample based、hemisphere-sample based(cos angle weight) and linear-sample based(distance weight), this is the simple sphere-sample based method
[numthreads(8, 8, 1)]
void SSAO(uint3 id : SV_DispatchThreadID) {
    float3 sample_sphere[16] = {
        float3(0.5381, 0.1856,-0.4319), float3(0.1379, 0.2486, 0.4430),
        float3(0.3371, 0.5679,-0.0057), float3(-0.6999,-0.0451,-0.0019),
        float3(0.0689,-0.1598,-0.8547), float3(0.0560, 0.0069,-0.1843),
        float3(-0.0146, 0.1402, 0.0762), float3(0.0100,-0.1924,-0.0344),
        float3(-0.3577,-0.5301,-0.4358), float3(-0.3169, 0.1063, 0.0158),
        float3(0.0103,-0.5869, 0.0046), float3(-0.0897,-0.4940, 0.3287),
        float3(0.7119,-0.0154,-0.0918), float3(-0.0533, 0.0596,-0.5411),
        float3(0.0352,-0.0631, 0.5460), float3(-0.4776, 0.2847,-0.0271)
    };
    float2 screenUV = id.xy / (_CameraBufferSize.zw / downSample);
    float4 depthNormalTexture = SAMPLE_TEXTURE2D_LOD(_CameraDepthNormalTexture, sampler_point_clamp, screenUV, 0);
    //depth of the DepthNormal is not realiabe, maybe sample Depth Texture instead
    float4 depthTexture = SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, sampler_point_clamp, screenUV, 0);
    float3 bufferNormal = DecodeViewNormalStereo(depthNormalTexture);
    //float bufferDepth = DecodeFloatRG(depthNormalTexture.zw);
    float bufferDepth = depthTexture.r;
    //Linear01Depth get [0,1] depth, LinearEyeDepth get [near, far] depth
    float linearDepth = LinearEyeDepth(bufferDepth, _ZBufferParams);
    float linear01Depth = Linear01Depth(bufferDepth, _ZBufferParams);
    //reconstruct view space position
    float3 bufferPosition = UvToViewSpace(screenUV, linear01Depth);
    float3 random = normalize(SAMPLE_TEXTURE2D_LOD(RandomTexture, sampler_linear_clamp, screenUV, 0).rgb);
    random = normalize(SAMPLE_TEXTURE2D_LOD(RandomTexture, sampler_linear_repeat, screenUV + random, 0).rgb);
    //NOTE : need this matrix to transform the sample vectors from tangent space to view space, but I do not know how
    float3 normal = normalize(bufferNormal);
    float3 tangent = normalize(random - normal * dot(random, normal));
    float3 binormal = cross(bufferNormal, tangent);
    float3x3 tbn = float3x3(tangent, binormal, normal);
    float occlusion = 0.0;
    for (int i = 0; i < 16; i++) {
        float3 ray = aoRadius * normalize(reflect(sample_sphere[i], random));
        ray = mul(tbn, ray);
        //invert positive direction ray
        float3 samplePositionVS = bufferPosition + ray;
        //project sample point into clip space
        float4 samplePositionCS = mul(_CameraProjection, float4(samplePositionVS, 1));
        samplePositionCS.xy /= samplePositionCS.w;
        samplePositionCS.xy *= 0.5;
        samplePositionCS.xy += 0.5;
        //get sample point scene depth
        float sampleDepth = SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, sampler_point_clamp, samplePositionCS.xy, 0);
        sampleDepth = LinearEyeDepth(sampleDepth, _ZBufferParams);
        float sampleDistance = -samplePositionVS.z;
        float difference = sampleDistance - sampleDepth;
        //weight by cos angle
        float weight = smoothstep(0.001, contrast, aoRadius / dot(ray, normal));
        occlusion +=  weight * step(0.001, difference);
    }
    float ao = 1 - magnitude * occlusion / 16;
    ao = saturate(ao + bias);
    ao = pow(ao, power);
    AmbientOcclusionRT[id.xy] = ao.xxx;
}

float3 GetSource(float2 screenUV) {
    return SAMPLE_TEXTURE2D_LOD(aoResult, sampler_linear_clamp, screenUV, 0);
}

float3 GetNormal(float2 screenUV) {
    float4 depthNormal = SAMPLE_TEXTURE2D_LOD(_CameraDepthNormalTexture, sampler_point_clamp, screenUV, 0);
    float3 normal = DecodeViewNormalStereo(depthNormal);
    return normal;
}

float CompareNormal(float3 normal0, float3 normal1) {
    return smoothstep(filterFactor, 1.0, dot(normal0, normal1));
}

[numthreads(8, 8, 1)]
void BilateralFilter(uint3 id : SV_DispatchThreadID) {
    float2 delta = filterRadius * (_CameraBufferSize.xy * downSample);
    //[0,_CameraBufferSize-1] -> screen [0,1] uv
    float2 uv = id.xy / (_CameraBufferSize.zw / downSample);
    float2 uv0a = uv - delta;
    float2 uv0b = uv + delta;
    float2 uv1a = uv - 2.0 * delta;
    float2 uv1b = uv + 2.0 * delta;
    float2 uv2a = uv - 3.0 * delta;
    float2 uv2b = uv + 3.0 * delta;
    //get normal
    float3 normal = GetNormal(uv);
    float3 normal0a = GetNormal(uv0a);
    float3 normal0b = GetNormal(uv0b);
    float3 normal1a = GetNormal(uv1a);
    float3 normal1b = GetNormal(uv1b);
    float3 normal2a = GetNormal(uv2a);
    float3 normal2b = GetNormal(uv2b);
    //get source
    float3 source = GetSource(uv);
    float3 source0a = GetSource(uv0a);
    float3 source0b = GetSource(uv0b);
    float3 source1a = GetSource(uv1a);
    float3 source1b = GetSource(uv1b);
    float3 source2a = GetSource(uv2a);
    float3 source2b = GetSource(uv2b);
    //calculate weight
    float w = 0.37004005286;
    float w0a = CompareNormal(normal, normal0a) * 0.31718061674;
    float w0b = CompareNormal(normal, normal0b) * 0.31718061674;
    float w1a = CompareNormal(normal, normal1a) * 0.19823788546;
    float w1b = CompareNormal(normal, normal1b) * 0.19823788546;
    float w2a = CompareNormal(normal, normal2a) * 0.11453744493;
    float w2b = CompareNormal(normal, normal2b) * 0.11453744493;
    float3 result = w * source;
    result += w0a * source0a;
    result += w0b * source0b;
    result += w1a * source1a;
    result += w1b * source1b;
    result += w2a * source2a;
    result += w2b * source2b;
    result = result / (w + w0a + w0b + w1a + w1b + w2a + w2b);
    FilteredResult[id.xy] = result;
}

float3 MinDiff(float3 p, float3 p1, float3 p2) {
    float3 v1 = p1 - p;
    float3 v2 = p - p2;
    return (length(v1) < length(v2)) ? v1 : v2;
}

float2 RotateDirections(float2 dir, float2 CosSin) {
    return float2(
        dir.x * CosSin.x - dir.y * CosSin.y, 
        dir.x * CosSin.y + dir.y * CosSin.x
        );
}

float2 SnapUVOffset(float2 uv, float2 bufferSize, float2 invBufferSize) {
    return floor(uv * bufferSize + 0.5) * invBufferSize;
}

float GetTangent(float3 v) {
    //tange(V) = Vz/Vxy
    return v.z * rsqrt(dot(v.xy, v.xy));
}

float TanToSin(float x) {
    return x * rsqrt(x * x + 1.0);
}

float FallOff(float distance) {
    return 1 - (distance * distance) / (aoRadius * aoRadius);
}

[numthreads(8, 8, 1)]
void HBAO(uint3 id : SV_DispatchThreadID) {
    float2 bufferSize = _CameraBufferSize.zw / downSample;
    float2 invBufferSize = _CameraBufferSize.xy * downSample;
    float2 screenUV = id.xy / bufferSize;
    float4 depthNormalTexture = SAMPLE_TEXTURE2D_LOD(_CameraDepthNormalTexture, sampler_point_clamp, screenUV, 0);
    //depth of the DepthNormal is not realiabe, maybe sample Depth Texture instead
    float4 depthTexture = SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, sampler_point_clamp, screenUV, 0);
    float3 bufferNormal = DecodeViewNormalStereo(depthNormalTexture);
    //float bufferDepth = DecodeFloatRG(depthNormalTexture.zw);
    float bufferDepth = depthTexture.r;
    //Linear01Depth get [0,1] depth, LinearEyeDepth get [near, far] depth
    float linearDepth = LinearEyeDepth(bufferDepth, _ZBufferParams);
    float linear01Depth = Linear01Depth(bufferDepth, _ZBufferParams);
    //point and surroundings
    float3 p, pr, pl, pt, pb;
    p = UvToViewSpace(screenUV, linear01Depth);
    pr = UvToViewSpace(screenUV + float2(invBufferSize.x, 0), linear01Depth);
    pl = UvToViewSpace(screenUV + float2(-invBufferSize.x, 0), linear01Depth);
    pt = UvToViewSpace(screenUV + float2(0, invBufferSize.y), linear01Depth);
    pb = UvToViewSpace(screenUV + float2(0, -invBufferSize.y), linear01Depth);
    //get view space position delta of the point p in screen space
    float3 dpdu = MinDiff(p, pr, pl);
    float3 dpdv = MinDiff(p, pt, pb) * _CameraBufferSize.x * _CameraBufferSize.w;
    //random is used to offset sample direction
    float3 random = normalize(SAMPLE_TEXTURE2D_LOD(RandomTexture, sampler_linear_clamp, screenUV, 0).rgb);
    random = normalize(SAMPLE_TEXTURE2D_LOD(RandomTexture, sampler_linear_repeat, screenUV + random, 0).rgb);
    //calculate the projected size of the hemisphere
    float2 sampleRadiusUV = 0.5 * aoRadius * CameraNearPlane / linearDepth;
    float radiusPixel = sampleRadiusUV.x * (_CameraBufferSize.zw / downSample);
    float ao = 1.0;
    //make sure the radius of the projected hemisphere is more than a pixel
    if (radiusPixel > 1.0) {
        //avoid oversampling if numSteps is greater than the kernel radius in pixels
        float numSteps = min(sampleCount, radiusPixel);
        //divide by Ns+1 so that the farthest samples are not fully attenuated(normally numSteps is equal to sampleCount)
        float stepSizePix = radiusPixel / (numSteps + 1);
        //clamp numSteps if it is greater than the max kernel footprint
        float maxNumSteps = maxRadiusPixels / stepSizePix;
        if (maxNumSteps < numSteps) {
            //use dithering to avoid AO discontinuities
            numSteps = floor(maxNumSteps + random.z);
            numSteps = max(numSteps, 1);
            stepSizePix = maxRadiusPixels / numSteps;
        }
        //step size in uv space
        float2 stepSize = stepSizePix * invBufferSize;
        //radius diff
        float alpha = 2.0 * PI / numDirections;
        //calculate the horizon occlusion of each direction
        for (int i = 0; i < numDirections; ++i) {
            float theta = alpha * i;
            //random offset the direction
            float2 dir = RotateDirections(float2(cos(theta), sin(theta)), random.xy);
            float2 deltaUV = dir * stepSize;
            //offset sample start point
            float2 uv = screenUV + SnapUVOffset(random.xy * deltaUV, bufferSize, invBufferSize);
            deltaUV = SnapUVOffset(deltaUV, bufferSize, invBufferSize);
            //calculate the tangent vector
            float3 T = deltaUV.x * dpdu + deltaUV.y * dpdv;
            //get the angle of tangent vector from the view space axis
            float tanT = GetTangent(T) + tanBias;
            float sinT = TanToSin(tanT);
            //get horizontal vector
            float3 H;
            float tanH;
            float dist;
            for (int j = 1; j <= sampleCount; ++j) {
                uv += deltaUV;
                float depth = SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, sampler_point_clamp, uv, 0);
                depth = Linear01Depth(depth, _ZBufferParams);
                H = UvToViewSpace(uv, depth);
                //horizontal ray from sample point
                tanH = GetTangent(H - p);
                dist = length(H - p);
                if (dist < aoRadius && tanH > tanT) {
                    float sinH = TanToSin(tanH);
                    ao += FallOff(dist) * (sinH - sinT);
                    tanT = tanH;
                    sinT = sinH;
                }
            }
        }
        ao = 1.0 - ao / numDirections * hbaoStrength;
    }

    AmbientOcclusionRT[id.xy] = ao.xxx;
}

void GetAoAndDepth(float2 uv, inout float ao, inout float depth) {
    ao = SAMPLE_TEXTURE2D_LOD(aoResult, sampler_linear_clamp, uv, 0);
    depth = SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, sampler_point_clamp, uv, 0);
    depth = Linear01Depth(depth, _ZBufferParams);
}

float CrossBilateralWeight(float r, float d, float d0) {
    float blurSigma = filterRadius * 0.5;
    float blurFalloff = 1.0 / (2.0 * blurSigma * blurSigma);
    float dz = (d0 - d) * _ProjectionParams.z * filterFactor;
    return exp2(-r * r * blurFalloff - dz * dz);
}